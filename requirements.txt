--extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu124
llama-cpp-python -C cmake.args="-DGGML_CUDA=on"
pillow
thefuzz
opencv-python
fastapi 
uvicorn 
jinja2 
python-multipart
aiofiles